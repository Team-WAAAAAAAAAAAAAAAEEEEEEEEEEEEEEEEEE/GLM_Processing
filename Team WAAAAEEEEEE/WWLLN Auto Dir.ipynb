{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\")) # makes the notebook fill the whole window\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib import ticker\n",
    "from matplotlib.collections import PatchCollection\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.patches import Polygon\n",
    "from sklearn.cluster import DBSCAN\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import time\n",
    "import shapefile\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, isdir, join\n",
    "import CubicSplineTrack\n",
    "from greatcircle import great_circle\n",
    "from datetime import date\n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#Turn off interactive plotting for pyplot\n",
    "plt.ioff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Storms Found: 34\n",
      "['Hurricane Arthur', 'Hurricane Bertha', 'Hurricane Beta', 'Hurricane Cristobal', 'Hurricane Delta', 'Hurricane Dolly', 'Hurricane Edouard', 'Hurricane Epsilon', 'Hurricane Eta', 'Hurricane Fay', 'Hurricane Five', 'Hurricane Gamma', 'Hurricane Gonzalo', 'Hurricane Hanna', 'Hurricane Iota', 'Hurricane Isaias', 'Hurricane Josephine', 'Hurricane Kyle', 'Hurricane Laura', 'Hurricane Marco', 'Hurricane Nana', 'Hurricane Omar', 'Hurricane Paulette', 'Hurricane Rene', 'Hurricane Sally', 'Hurricane Teddy', 'Hurricane Ten', 'Hurricane Theta', 'Hurricane Twenty', 'Hurricane Twenty-Eig', 'Hurricane Twenty-Nin', 'Hurricane Vicky', 'Hurricane Wilfred', 'Hurricane Zeta']\n"
     ]
    }
   ],
   "source": [
    "check_minutes = 60 # minuite var\n",
    "split_storm = 1 # seperate or no\n",
    "\n",
    "only_dirs = [d for d in listdir(\"Data/\") if isdir(join(\"Data/\", d))] # makes a list of all the folders in Data/\n",
    "dir_count = len(only_dirs)\n",
    "\n",
    "WWLLN_Track_Path = [\"\"] * dir_count # the paths of all the track files, in the same order as only_dirs\n",
    "WWLLN_Locations_Path = [\"\"] * dir_count # the paths of all the lightning locations files, in the same order as only_dirs\n",
    "Cubic_Spline_Path = [\"\"] * dir_count # the paths of all the cubic spline files, in the same order as only_dirs\n",
    "\n",
    "Image_Path = [\"\"] * dir_count # Base Image paths\n",
    "Storm_Names = [\"\"] * dir_count # Base storm names\n",
    "\n",
    "# loop thru all dirs\n",
    "storms_found = 0\n",
    "dir_indx = 0\n",
    "while dir_indx < dir_count:\n",
    "    \n",
    "    # this gets all the file paths in a given storms' folder\n",
    "    only_dirs[dir_indx] = join(\"Data/\", only_dirs[dir_indx])\n",
    "    file_paths = listdir(only_dirs[dir_indx])\n",
    "    \n",
    "    # check if the 3 nessisary files exist\n",
    "    if len(file_paths) < 2:\n",
    "        only_dirs[dir_indx] = \"\"\n",
    "        dir_indx+=1\n",
    "        continue\n",
    "    \n",
    "    #print(only_dirs[dir_indx])\n",
    "    #print(file_paths)\n",
    "    \n",
    "    # for every file in file_paths, sort it into its' respective arrays\n",
    "    file_indx = 0\n",
    "    files_found = 0\n",
    "    Cubic_Found = False\n",
    "    while file_indx < len(file_paths):\n",
    "        # creates the files full path\n",
    "        file_paths[file_indx] = join(only_dirs[dir_indx]+\"/\", file_paths[file_indx])\n",
    "        #print(file_paths[file_indx])\n",
    "        \n",
    "        # sorts the file path based on the last expected word of a file and it's type\n",
    "        if file_paths[file_indx].endswith(\"Trackfile.txt\"):\n",
    "            WWLLN_Track_Path[dir_indx] = file_paths[file_indx]\n",
    "            files_found+=1\n",
    "            \n",
    "            # generates the name of the storm for images\n",
    "            Storm_Names[dir_indx] = \"Hurricane \" + WWLLN_Track_Path[dir_indx].rsplit(\"_\", 3)[1]\n",
    "            \n",
    "        elif file_paths[file_indx].endswith(\"Locations.txt\"):\n",
    "            WWLLN_Locations_Path[dir_indx] = file_paths[file_indx]\n",
    "            files_found+=1\n",
    "            \n",
    "        elif file_paths[file_indx].endswith(\"Trackfile.csv\"):\n",
    "            Cubic_Spline_Path[dir_indx] = file_paths[file_indx]\n",
    "            Cubic_Found = True\n",
    "            files_found+=1\n",
    "        #print(f\"File: {file_paths[file_indx]}, Storm indx: {dir_indx}\\n\")\n",
    "        file_indx+=1\n",
    "    \n",
    "    # Run with Bens' Cubic Spline\n",
    "    if not Cubic_Found:\n",
    "        Cubic_Spline_Path[dir_indx] = join(only_dirs[dir_indx]+\"/\", Storm_Names[dir_indx] + \" Cubic Spline Trackfile.csv\")\n",
    "        #print(WWLLN_Track_Path[dir_indx])\n",
    "        CubicSplineTrack.cubic_spline_trackfile(WWLLN_Track_Path[dir_indx], Cubic_Spline_Path[dir_indx], check_minutes)\n",
    "        files_found+=1\n",
    "    \n",
    "    if files_found != 3:\n",
    "        print(f\"Incorrect files found: {files_found}, {file_paths}\\n\")\n",
    "        only_dirs[dir_indx] = \"\"\n",
    "        dir_indx+=1\n",
    "        continue\n",
    "    \n",
    "    # makes the path for this index's storm\n",
    "    Image_Path[dir_indx] = join(\"./Images/\", Storm_Names[dir_indx])\n",
    "    if split_storm:\n",
    "        Image_Path[dir_indx] = Image_Path[dir_indx] + \" Split \" + str(check_minutes) +\" Minutes\"\n",
    "    else:\n",
    "        Image_Path[dir_indx] = Image_Path[dir_indx] + \" \" + str(check_minutes) +\" Minutes\"\n",
    "    \n",
    "    # if an image folder |dosen't| exist, create a new one with the path at Image_Path[dir_indx]\n",
    "    if not os.path.exists(Image_Path[dir_indx]):\n",
    "        os.mkdir(Image_Path[dir_indx])\n",
    "    \n",
    "    Image_Path[dir_indx] = Image_Path[dir_indx] + \"/\" # add a slash for use in the next block, making the actual img paths\n",
    "    \n",
    "    #print('\\n')\n",
    "    storms_found+=1\n",
    "    dir_indx+=1\n",
    "\n",
    "# print for debug\n",
    "print(f\"Storms Found: {storms_found}\")\n",
    "print(Storm_Names)\n",
    "#print(Image_Path)\n",
    "#print(WWLLN_Track_Path)\n",
    "#print(WWLLN_Locations_Path)\n",
    "#print(Cubic_Spline_Path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_circle(row, center_lat, center_lon): \n",
    "    lat = (row['Lat'])\n",
    "    lon = (row['Long'])\n",
    "    return great_circle(lat, lon, center_lat, center_lon)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent Done:  100.00%\tTime taken:  1.12 seconds\tEst time remaining: 0:00:00 00417 0146\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-2b89c286441d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[1;31m# This loads the WWLLN lighting location data that Jeremy and Natalia give us\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[0mln\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mWWLLN_Locations_Path\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdir_indx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Year\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"Month\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"Day\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"Hour\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"Min\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"Sec\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"Lat\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"Long\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"Dist_East_West\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"Dist_North_South\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlow_memory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m     \u001b[0mln\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Date'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mln\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{int(x['Year'])}-{int(x['Month'])}-{int(x['Day'])}-{int(x['Hour'])}-{int(x['Min'])}-{x['Sec']}\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"%Y-%m-%d-%H-%M-%S.%f\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#is a data clean\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[1;31m# This opens the cubic spline trackfiles that Ben creates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, axis, raw, result_type, args, **kwds)\u001b[0m\n\u001b[0;32m   7766\u001b[0m             \u001b[0mkwds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7767\u001b[0m         )\n\u001b[1;32m-> 7768\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   7769\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7770\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapplymap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mna_action\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mget_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    183\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 185\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_empty_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    274\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    275\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 276\u001b[1;33m         \u001b[0mresults\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mres_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    277\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    278\u001b[0m         \u001b[1;31m# wrap results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply_series_generator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    288\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    289\u001b[0m                 \u001b[1;31m# ignore SettingWithCopy here in case the user mutates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 290\u001b[1;33m                 \u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    291\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    292\u001b[0m                     \u001b[1;31m# If we have a view on v, we need to make a copy because\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-21-2b89c286441d>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[1;31m# This loads the WWLLN lighting location data that Jeremy and Natalia give us\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[0mln\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mWWLLN_Locations_Path\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdir_indx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Year\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"Month\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"Day\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"Hour\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"Min\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"Sec\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"Lat\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"Long\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"Dist_East_West\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"Dist_North_South\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlow_memory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m     \u001b[0mln\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Date'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mln\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{int(x['Year'])}-{int(x['Month'])}-{int(x['Day'])}-{int(x['Hour'])}-{int(x['Min'])}-{x['Sec']}\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"%Y-%m-%d-%H-%M-%S.%f\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#is a data clean\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[1;31m# This opens the cubic spline trackfiles that Ben creates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py\u001b[0m in \u001b[0;36mto_datetime\u001b[1;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[0;32m    830\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvert_listlike\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    831\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 832\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvert_listlike\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    833\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    834\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py\u001b[0m in \u001b[0;36m_convert_listlike_datetimes\u001b[1;34m(arg, format, name, tz, unit, errors, infer_datetime_format, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[0;32m    480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m     \u001b[0mutc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtz\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"utc\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 482\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_box_as_indexlike\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mutc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mutc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    483\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py\u001b[0m in \u001b[0;36m_box_as_indexlike\u001b[1;34m(dt_array, utc, name)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mis_datetime64_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdt_array\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[0mtz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"utc\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mutc\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mDatetimeIndex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdt_array\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtz\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtz\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mIndex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdt_array\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\datetimes.py\u001b[0m in \u001b[0;36m__new__\u001b[1;34m(cls, data, freq, tz, normalize, closed, ambiguous, dayfirst, yearfirst, dtype, copy, name)\u001b[0m\n\u001b[0;32m    305\u001b[0m         \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmaybe_extract_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 307\u001b[1;33m         dtarr = DatetimeArray._from_sequence_not_strict(\n\u001b[0m\u001b[0;32m    308\u001b[0m             \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m             \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\datetimes.py\u001b[0m in \u001b[0;36m_from_sequence_not_strict\u001b[1;34m(cls, data, dtype, copy, tz, freq, dayfirst, yearfirst, ambiguous)\u001b[0m\n\u001b[0;32m    324\u001b[0m         \u001b[0mfreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfreq_infer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdtl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaybe_infer_freq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfreq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 326\u001b[1;33m         subarr, tz, inferred_freq = sequence_to_dt64ns(\n\u001b[0m\u001b[0;32m    327\u001b[0m             \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    328\u001b[0m             \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\datetimes.py\u001b[0m in \u001b[0;36msequence_to_dt64ns\u001b[1;34m(data, dtype, copy, tz, dayfirst, yearfirst, ambiguous)\u001b[0m\n\u001b[0;32m   1985\u001b[0m     \u001b[1;31m# `data` may have originally been a Categorical[datetime64[ns, tz]],\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1986\u001b[0m     \u001b[1;31m# so we need to handle these types.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1987\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mis_datetime64tz_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1988\u001b[0m         \u001b[1;31m# DatetimeArray -> ndarray\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1989\u001b[0m         \u001b[0mtz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_maybe_infer_tz\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtz\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\dtypes\\common.py\u001b[0m in \u001b[0;36mis_datetime64tz_dtype\u001b[1;34m(arr_or_dtype)\u001b[0m\n\u001b[0;32m    418\u001b[0m     \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    419\u001b[0m     \"\"\"\n\u001b[1;32m--> 420\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr_or_dtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mExtensionDtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    421\u001b[0m         \u001b[1;31m# GH#33400 fastpath for dtype object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    422\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0marr_or_dtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"M\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "TODO:\n",
    "-sort output by intensity (Dvorac scale?) 1-5\n",
    "-use great circle\n",
    "-title bigger\n",
    "\"\"\"\n",
    "# for every storm, do the things\n",
    "dir_indx = 0\n",
    "while dir_indx < dir_count:\n",
    "    # if storm is invalid, skip doin the things\n",
    "    if only_dirs[dir_indx] == \"\":\n",
    "        dir_indx+=1\n",
    "        continue\n",
    "    \n",
    "    # This loads the WWLLN trackfile Jeremy and Natalia give us\n",
    "    # wind = nautical mph, pressure = millibars\n",
    "    df = pd.read_csv(WWLLN_Track_Path[dir_indx], header=None, names=[\"Year\",\"Month\",\"Day\",\"Hour\",\"Lat\",\"Long\",\"Min_Pressure\",\"Max_Winds\",\"Unused\"], low_memory=False, sep='\\t')\n",
    "    df = df.drop(\"Unused\", axis=1)#data filtering\n",
    "    df['Date'] = df.apply(lambda x: pd.to_datetime(f\"{int(x['Year'])}-{int(x['Month'])}-{int(x['Day'])}-{int(x['Hour'])}\", format=\"%Y-%m-%d-%H\"), axis=1)\n",
    "    \n",
    "    #wind pressure stuff \n",
    "    #run pressure wind speed function on df for every row, save into array \n",
    "    #make dataframe \n",
    "    dates = df['Date']\n",
    "    #loop through df, for every row, check date \n",
    "    df_length = len(df.columns)\n",
    "    left_half_dates = [date.min] * df_length\n",
    "    right_half_dates = [date.min] * df_length\n",
    "    row_index = 1 \n",
    "    left_half_dates[0] = date.min\n",
    "    right_half_dates[df_length - 1] = date.max\n",
    "    while row_index < df_length: \n",
    "        left_half_dates[row_index] = dates.iloc[row_index - 1] + ((dates.iloc[row_index] - dates.iloc[row_index - 1]) / 2)\n",
    "        row_index += 1\n",
    "    row_index = 0\n",
    "    while row_index < df_length - 1: \n",
    "        right_half_dates[row_index] = dates.iloc[row_index] + ((dates.iloc[row_index] - dates.iloc[row_index + 1]) / 2)\n",
    "        row_index += 1\n",
    "    \n",
    "    # This loads the WWLLN lighting location data that Jeremy and Natalia give us\n",
    "    ln = pd.read_csv(WWLLN_Locations_Path[dir_indx], header=None, names=[\"Year\",\"Month\",\"Day\",\"Hour\",\"Min\",\"Sec\",\"Lat\",\"Long\",\"Dist_East_West\",\"Dist_North_South\"], low_memory=False, sep=' ')\n",
    "    ln['Date'] = ln.apply(lambda x: pd.to_datetime(f\"{int(x['Year'])}-{int(x['Month'])}-{int(x['Day'])}-{int(x['Hour'])}-{int(x['Min'])}-{x['Sec']}\", format=\"%Y-%m-%d-%H-%M-%S.%f\"), axis=1)#is a data clean\n",
    "\n",
    "    # This opens the cubic spline trackfiles that Ben creates\n",
    "    storm_center = pd.read_csv(Cubic_Spline_Path[dir_indx])\n",
    "    storm_center['Date'] = storm_center['Date'].apply(pd.to_datetime)\n",
    "\n",
    "    # Genereates the list of dates from the WWLLN trackfile of a (check_minutes) range\n",
    "    dates = pd.date_range(df['Date'][0], df['Date'][len(df)-1], freq=str(check_minutes)+\"T\")\n",
    "    \n",
    "    buffer = 10\n",
    "    #if split_storm:\n",
    "        #buffer = 6 # affects map zooooooooooooom\n",
    "    shp_file = \"World_Countries__Generalized_-shp/World_Countries__Generalized_\" # Map file ???????\n",
    "    cmap = 'gist_ncar' # dunno WHAT this is\n",
    "\n",
    "    # Counter and iteration\n",
    "    for index, date in enumerate(dates): # this loop makes one image for every (check_minutes) amount of time\n",
    "        starttime = time.perf_counter() # speeed timer start\n",
    "        center = storm_center[storm_center['Date'] == date] # storm center at this time frame\n",
    "        \n",
    "        if split_storm:\n",
    "            ln_curr_timeframe = ln[(ln['Date'] >= date) & (ln['Date'] < date + datetime.timedelta(minutes=check_minutes))]\n",
    "            #print(ln_curr_timeframe)\n",
    "            if len(ln_curr_timeframe) != 0:\n",
    "                ln_curr_timeframe['Distance'] = ln_curr_timeframe.apply(run_circle, axis = 1, args = ((center['Lat']), (center['Long'])))\n",
    "                #print(ln_curr_timeframe)\n",
    "                subset = ln_curr_timeframe[(ln_curr_timeframe['Distance'] <= 100 / 1.852) | ((ln_curr_timeframe['Distance'] >= 200 / 1.852) & (ln_curr_timeframe['Distance'] <= 400 / 1.852))]\n",
    "            else:\n",
    "                subset = ln_curr_timeframe\n",
    "        else:\n",
    "            # Select just the lightning locations that are within (check_minutes) minutes\n",
    "            subset = ln[(ln['Date'] >= date) & (ln['Date'] < date + datetime.timedelta(minutes=check_minutes))]\n",
    "        \n",
    "        # if lightning exists, do dbscan on it\n",
    "        if len(subset != 0):\n",
    "            dbscan = DBSCAN(eps=.2, min_samples=3)\n",
    "            subset['Labels'] = dbscan.fit_predict(subset[['Long','Lat']])\n",
    "\n",
    "        # Setup the figure\n",
    "        fig, ax = plt.subplots(figsize=(15,15))\n",
    "        \n",
    "        # this is for the coastline\n",
    "        # This reads the shapefile, extracts each shape, creates a polygon, and adds it to the list\n",
    "        sf = shapefile.Reader(shp_file)\n",
    "        shapes = sf.shapes()\n",
    "        Nshp = len(shapes)\n",
    "        ptchs = []\n",
    "        for nshp in range(Nshp):\n",
    "            pts = np.array(shapes[nshp].points)\n",
    "            prt = shapes[nshp].parts\n",
    "            par = list(prt) + [pts.shape[0]]\n",
    "            for pij in range(len(prt)):# <--------------------------------------------------------------------------------------------------------------------------- FIX ME (im slow) use while loops, never range()!\n",
    "                ptchs.append(Polygon(pts[par[pij]:par[pij+1]]))\n",
    "        # Every every polygon from the shapefile to figure\n",
    "        ax.add_collection(PatchCollection(ptchs, facecolor= '#838688', edgecolor='k', linewidths=1., zorder=2))\n",
    "\n",
    "        # This adds the water color\n",
    "        ax.add_patch(mpl.patches.Rectangle((-180,-89),360,180,color='#a6cae0'))\n",
    "\n",
    "        # This connects Antarcitca to the bottom of the image\n",
    "        ax.add_patch(mpl.patches.Rectangle((-179.9,-89.9),360,2,color='#838688',zorder=3))\n",
    "\n",
    "        # These are more general image settings\n",
    "        plt.title(Storm_Names[dir_indx]+' '+str(date), fontdict = {'fontsize' : 40})\n",
    "\n",
    "        #edges = (-180,180,-90,90) # Left, Right, Bottom, Top | Set this if you want to change the map scale\n",
    "        edges = (center['Long'].values[0] - buffer, center['Long'].values[0] + buffer, center['Lat'].values[0] - buffer, center['Lat'].values[0] + buffer) # <--------------------------This affects map zoooooooooom\n",
    "\n",
    "        # setting up img stuff, prob shouldn't be touched\n",
    "        xlim = np.append(np.arange(edges[0], edges[1], step=2.5), edges[1])\n",
    "        ylim = np.append(np.arange(edges[2], edges[3], step=2.5), edges[3])\n",
    "        ax.set_xticks(xlim)\n",
    "        ax.set_yticks(ylim)\n",
    "        ax.set_xlim(edges[0], edges[1])\n",
    "        ax.set_ylim(edges[2], edges[3])\n",
    "        ax.xaxis.set_major_formatter(ticker.FormatStrFormatter('%.2f'))\n",
    "        ax.yaxis.set_major_formatter(ticker.FormatStrFormatter('%.2f'))\n",
    "        plt.rc('xtick', labelsize=30)\n",
    "        plt.rc('ytick', labelsize=30)\n",
    "\n",
    "        # if lightning exists, put it in the image\n",
    "        if len(subset) != 0:\n",
    "            plt.scatter(subset['Long'], subset['Lat'], c=subset['Labels'], cmap=cmap, zorder=4) # plots the dbscan data\n",
    "        \n",
    "        #plt.scatter(subset['Long'],subset['Lat'],s=100,c=\"yellow\",edgecolors='black',zorder=5) # <- old plot func for non-grouped data\n",
    "        plt.scatter(center['Long'], center['Lat'], s=140, c=\"red\", edgecolors='black' ,zorder=5, alpha=0.5) # plots the center of the storm\n",
    "\n",
    "        # save and close the image\n",
    "        plt.savefig(Image_Path[dir_indx] + str(index), bbox_inches='tight', pad_inches=.4)\n",
    "        plt.close('all')\n",
    "\n",
    "        # Shows roughly how long we have left\n",
    "        taken = time.perf_counter() - starttime\n",
    "        print(f\"Percent Done: {(index + 1) / len(dates) * 100 : .2f}%\\tTime taken: {taken : .2f} seconds\\tEst time remaining: {datetime.timedelta(seconds=(len(dates) - (index + 1)) * taken)} {len(subset)}\", end='\\r')\n",
    "    dir_indx+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T-Number</th>\n",
       "      <th>1-min Winds</th>\n",
       "      <th>Min. Pressure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.5</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>30</td>\n",
       "      <td>1009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.5</td>\n",
       "      <td>35</td>\n",
       "      <td>1005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>45</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.5</td>\n",
       "      <td>55</td>\n",
       "      <td>994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.0</td>\n",
       "      <td>65</td>\n",
       "      <td>987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.5</td>\n",
       "      <td>77</td>\n",
       "      <td>979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>90</td>\n",
       "      <td>970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5.5</td>\n",
       "      <td>102</td>\n",
       "      <td>960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6.0</td>\n",
       "      <td>115</td>\n",
       "      <td>948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>6.5</td>\n",
       "      <td>127</td>\n",
       "      <td>935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>7.0</td>\n",
       "      <td>140</td>\n",
       "      <td>921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7.5</td>\n",
       "      <td>155</td>\n",
       "      <td>906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>8.0</td>\n",
       "      <td>170</td>\n",
       "      <td>890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>8.5</td>\n",
       "      <td>185</td>\n",
       "      <td>873</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    T-Number  1-min Winds  Min. Pressure\n",
       "0        1.5           25              0\n",
       "1        2.0           30           1009\n",
       "2        2.5           35           1005\n",
       "3        3.0           45           1000\n",
       "4        3.5           55            994\n",
       "5        4.0           65            987\n",
       "6        4.5           77            979\n",
       "7        5.0           90            970\n",
       "8        5.5          102            960\n",
       "9        6.0          115            948\n",
       "10       6.5          127            935\n",
       "11       7.0          140            921\n",
       "12       7.5          155            906\n",
       "13       8.0          170            890\n",
       "14       8.5          185            873"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating intensity table\n",
    "intensity_values = {\n",
    "     'T-Number': [1.5, 2, 2.5, 3, 3.5, 4, 4.5, 5, 5.5, 6, 6.5, 7, 7.5, 8, 8.5],\n",
    "  '1-min Winds': [25, 30, 35, 45, 55, 65, 77, 90, 102, 115, 127, 140, 155, 170, 185],\n",
    "'Min. Pressure': [0, 1009, 1005, 1000, 994, 987, 979, 970, 960, 948, 935, 921, 906, 890, 873]\n",
    "}\n",
    "\n",
    "T_frame = pd.DataFrame(intensity_values)\n",
    "\n",
    "\n",
    "#Partial function implementation\n",
    "intensity = df[['Min_Pressure','Max_Winds']]\n",
    "intensity # .loc[0 , 'Min_Pressure']\n",
    "for i in range(37):\n",
    "    pressure = intensity.loc[i , 'Min_Pressure']\n",
    "    speed = intensity.loc[i , 'Max_Winds']\n",
    "    \n",
    "    \n",
    "#intensity\n",
    "#df\n",
    "T_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
